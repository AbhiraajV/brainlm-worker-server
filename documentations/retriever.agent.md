MASTER PROMPT — RETRIEVER AGENT (SEMANTIC QUERY COMPILER)
Context

You are building a semantic retriever agent for a “second brain” system.
This system stores user memory across multiple semantic layers, each capturing a different view of reality.

This is not a traditional RAG retriever.
This is not a router.
This is a semantic query compiler + evidence aggregator.

Your job is to design and implement a modular retriever agent that:

Accepts one or more questions (from user or from another LLM)

Compiles table-specific semantic queries

Searches all memory layers

Fetches deep, wide, causally-complete evidence

Returns structured context, not answers

The output will later be consumed by a synthesizer LLM.

Memory Layers (Databases)

The system has the following semantic layers (tables).
Each layer stores different kinds of meaning.

1. Event (FACTUAL LAYER)

What the user explicitly said or did

Time-stamped, immutable facts

Examples:

“I smoked two cigarettes at work”

“I went for a run in the morning”

“I fought with my girlfriend”

2. Interpretation (MEANING LAYER)

Rich semantic understanding of each event

Emotional states, motivations, implications

One interpretation per event

Embedded for semantic search

3. Pattern (ABSTRACTION LAYER)

Derived recurring structures across time

Behavioral, emotional, structural, logistical, preference-based patterns

Patterns can be:

Shallow (routines, schedules)

Deep (emotional coping, avoidance)

Structural (push/pull/legs split)

Patterns evolve but never reset

4. Analysis / Insights (OPTIONAL, FUTURE)

Question–answer style insights

Hypotheses, correlations, conclusions

Derived from events + interpretations + patterns

Core Principle (CRITICAL)

The retriever does NOT decide which table to query.
It ALWAYS queries ALL tables.

What changes is HOW it queries each table.

The same question means different things in different layers.

What This Agent Is NOT

❌ Not a keyword search

❌ Not tag-based

❌ Not rule-based routing

❌ Not a single embedding lookup

❌ Not an answer generator

What This Agent IS

A Semantic Query Compiler + Evidence Aggregator

Input

The retriever receives:

{
  "mainQuestion": "When do I smoke and how do I stop?",
  "subQuestions": [
    "When do I feel the urge to smoke?",
    "What usually happens before I smoke?",
    "What emotions are associated with smoking?",
    "What patterns exist around smoking?",
    "Has smoking increased or decreased over time?"
  ]
}


Sub-questions may be:

Generated by another LLM

Generated internally

Explicitly provided

Step 1 — Semantic Query Compilation (MOST IMPORTANT)

For each question, the retriever must ask an LLM to generate table-specific search intents.

Example

Question:

“When am I sad?”

The LLM must generate something like:

{
  "Event": {
    "searchIntent": "events where the user explicitly expressed sadness, low mood, demotivation, distress",
    "timeBias": "important",
    "sequenceBias": true
  },
  "Interpretation": {
    "searchIntent": "emotional states indicating sadness, hopelessness, emotional pain, grief, demotivation",
    "psychologicalFocus": true
  },
  "Pattern": {
    "searchIntent": "recurring emotional lows, depressive cycles, sadness patterns over time",
    "longTermFocus": true
  },
  "Analysis": {
    "searchIntent": "hypotheses or insights explaining sadness or emotional decline"
  }
}

RULES

Each table gets its own semantic query

No query reuse across tables

No hardcoded keywords

The LLM decides how to phrase the meaning

Step 2 — Embedding Generation (Per Table)

Each table-specific search intent is:

Embedded separately

Used only for that table

❗ Never reuse the same embedding across tables

Step 3 — Parallel Retrieval (ALL TABLES)

The retriever performs parallel semantic search on:

Event

Interpretation

Pattern

Analysis (if exists)

Each table has:

Different limits

Different relevance weighting

Example defaults:

Events → top 20

Interpretations → top 15

Patterns → top 10

Analysis → top 10

Step 4 — Event Expansion (VERY IMPORTANT)

Whenever an Event is retrieved:

The retriever MUST also fetch:

The event’s Interpretation

Any Patterns linked via PatternEvent

Any Analysis / Insights that reference:

That event

Its interpretation

Its patterns

This makes the retriever wide, not narrow.

Every event becomes a mini knowledge graph.

Step 5 — Evidence Normalization

All retrieved items must be normalized into a common structure:

{
  "source": "Event | Interpretation | Pattern | Analysis",
  "id": "...",
  "content": "...",
  "relatedEventId": "...",
  "timestamp": "...",
  "whyThisWasRetrieved": "Matched emotional distress related to sadness",
  "relevanceScore": 0.82
}


This enables:

UI rendering

Deduplication

Explainability

Trust

Step 6 — Deduplication & Coverage Control

Deduplicate near-identical items (cosine similarity > 0.95)

Ensure:

Recent evidence is included

Historical evidence is included

Pattern-linked evidence is included

Cap total evidence per question (e.g., 30–50 items)

Step 7 — Output (NO SYNTHESIS)

The retriever does NOT answer.

It outputs:

{
  "question": "When do I smoke and how do I stop?",
  "retrievedContext": {
    "events": [...],
    "interpretations": [...],
    "patterns": [...],
    "analysis": [...]
  }
}


This output is handed to a Synthesizer LLM.

Design Constraints

Modular: each step callable independently

Deterministic retrieval, non-deterministic reasoning

Table-agnostic extensibility (future layers can be added)

No schema changes required

No assumptions about domain (gym, health, relationships, etc.)

Mental Model Summary

Events = what happened

Interpretations = what it meant

Patterns = what repeats

Analysis = what it implies

Retriever = find everything that could matter

Synthesizer = decide what it means

Final Instruction

When implementing this retriever agent:

Think like a research assistant

Assume missing context is a bug

Prefer over-fetching with structure over under-fetching

Always search all layers

Always expand events into their semantic neighborhood

This retriever is the foundation of intelligence in the system.